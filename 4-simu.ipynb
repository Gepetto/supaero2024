{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b08843e-22d6-470b-8a00-5816543f5745",
   "metadata": {},
   "source": [
    "# Dynamics: simulation and control\n",
    "This notebook focuses on the simulation of polyarticulated systems, with final exercices where simple control laws have to be designed. The first part deals with collision detection using the hppfcl module of pinocchio. We then build a complete simulation engine for rigid unilateral contacts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d0f647-c9b2-46fd-8d3c-30ab56730076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB: as for all the tutorials, a magic command %do_not_load is introduced to hide\n",
      "    the solutions to some questions. Change it for %load if you want to see (and\n",
      "    execute) the solution.\n"
     ]
    }
   ],
   "source": [
    "import gepetuto.magic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b518ada-8e3a-4ca3-a723-573b3a08dab7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cd2485-7c55-4b12-bde3-54c9618de471",
   "metadata": {},
   "source": [
    "We will use several models in this tutorial:\n",
    "- a simple scene with 3 convex objects (buildSceneThreeBodies)\n",
    "- a variation of this first scene with more objects and walls (buildScenePillsBox)\n",
    "- a stack of cubes of various size (buildSceneCubes)\n",
    "- a robot hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ad858f-7312-43c8-9a3e-082b7b5ce34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp4.scenes import buildSceneThreeBodies, buildScenePillsBox, buildSceneCubes, buildSceneRobotHand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3530cb9f-3683-4e3f-8797-2974abf7a7ce",
   "metadata": {},
   "source": [
    "We rely on the HPP-FCL module of Pinocchio, which compute collision between geometries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6aa4d346-f6bd-4abf-b726-9244f34a0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hppfcl\n",
    "import pinocchio as pin\n",
    "import numpy as np\n",
    "import time\n",
    "from supaero2024.meshcat_viewer_wrapper import MeshcatVisualizer\n",
    "from tp4 import compatibility\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41615ac1-066c-4053-9dc6-3b32bec220a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## A basic example of collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f95e22-d485-455a-bcb1-b1839c75cdba",
   "metadata": {},
   "source": [
    "The goad of this section is to introduce a simple example of collision distances between bodies, and the underlying notions of witness points and segment and normal direction.\n",
    "\n",
    "Let's build a simple scene with 3 objects and display their proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea1e9b79-8d99-40a1-b32a-9a5ede9c9ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** You asked to start meshcat \"classically\" in tcp://127.0.0.1:6000\n",
      "*** Did you start meshcat manually (meshcat-server)\n",
      "Wrapper tries to connect to server <tcp://127.0.0.1:6000>\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "# %load tp4/generated/example_display_witness_build\n",
    "# Build a scene\n",
    "model,geom_model = buildSceneThreeBodies()\n",
    "data = model.createData()\n",
    "geom_data = geom_model.createData()\n",
    "\n",
    "# Start meshcat\n",
    "viz = MeshcatVisualizer(model=model, collision_model=geom_model,\n",
    "                        visual_model=geom_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c46cca4-e0e1-4237-8491-ef294aa49b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "q=pin.randomConfiguration(model)\n",
    "viz.display(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb423930-ee1a-4e6a-9c7f-558778e7a8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0786e388-2692-42be-aa29-87d0fc8f1f16",
   "metadata": {},
   "source": [
    "We can compute the distances between the 3 objects. Let's do it and show the closest points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07d43c00-17fd-4a10-88ee-b169031b8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp4.display_witness import DisplayCollisionWitnessesInMeshcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cce02cbf-b035-4b79-aaae-5b895dd87aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_display_witness_witness\n",
    "# Build the viewer add-on to display the witnesses.\n",
    "mcWitnesses = DisplayCollisionWitnessesInMeshcat(viz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec306059-8588-44e5-bc6f-5a87e194df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin.computeDistances(model,data,geom_model,geom_data,q)\n",
    "mcWitnesses.displayDistances(geom_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8350bd-2ad6-4096-99c2-5e9cad867f7f",
   "metadata": {},
   "source": [
    "Each collision pair corresponds to a pair of closets points, respectively located at the surface of the collision geometries if they are not colliding. These points are sometime called the *witness* points.\n",
    "\n",
    "The witness points are connected by the *witness* segment. This segment is normal to the two collision surfaces in the case the surface is smooth around the witness point. The normalized direction is called the collision *normal*. Its orientation is a convention (the most logical convention is to go from body 1 to body 2 of the collision pair)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c10fa58-6669-478d-80da-e845c3e9478b",
   "metadata": {},
   "source": [
    "Let's move the objects to better see these witness elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3286b67-e2ad-4bc4-a984-0eaf25b19cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_display_witness_trajectory\n",
    "v = (np.random.rand(model.nv)*2-1)*1e-3\n",
    "r0 = [ np.linalg.norm(q[7*i:7*i+3]) for i in range(model.nq//7) ]\n",
    "for t in range(100):\n",
    "\n",
    "    # Update the robot position along an arbitrary trajectory\n",
    "    q = pin.integrate(model,q,v*10)\n",
    "    for i in range(model.nq//7):\n",
    "        q[7*i:7*i+3] *= r0[i]/np.linalg.norm(q[7*i:7*i+3])\n",
    "    viz.display(q)\n",
    "\n",
    "    # Display the witness points\n",
    "    pin.computeDistances(model,data,geom_model,geom_data,q)\n",
    "    mcWitnesses.displayDistances(geom_data)\n",
    "\n",
    "    time.sleep(.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee975065-d25a-4eb5-9bc1-2613d3ca82ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Details about Pinocchio HPP-FCL "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d4e0c-754f-44ce-b0d4-d4d0f7bf329a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Let's see now how to extract the contact and distance information from Pinocchio and the module HPP-FCL, and how to store this in a proper data structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40fe852-9e16-4e06-a213-fb844b170098",
   "metadata": {},
   "source": [
    "### Geometry model\n",
    "The geometry model contains a set of object, each described by a name, a geometry primitive and a placement with respect to a parent joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39058748-2c4c-4ac4-91fc-8874235af3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Convex_1',\n",
       " 1,\n",
       " <hppfcl.hppfcl.Convex at 0x7f6ddc3ef610>,\n",
       "   R =\n",
       " 1 0 0\n",
       " 0 1 0\n",
       " 0 0 1\n",
       "   p = -1.18174e-05    0.0312635    0.0693724)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom1 = geom_model.geometryObjects[0]\n",
    "geom1.name, geom1.parentJoint, geom1.geometry, geom1.placement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77c0968-6e81-4993-9e95-08107cf2b70c",
   "metadata": {},
   "source": [
    "In addition, we also store the pairs of geometry objects that should be considered when evaluating collisions and distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b800e76-7029-464a-a54f-01ce712410bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[collision pair (0,1), collision pair (0,2), collision pair (1,2)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(geom_model.collisionPairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8ca8c5-7f24-469a-aa22-0b404aba41bd",
   "metadata": {},
   "source": [
    "### HPP-FCL computeDistances and computeCollisions\n",
    "The geometry algorithms are implemented in HPP-FCL under two different sets of functions, which respectively compute the distance between bodies, and the collision between bodies.\n",
    "When computing the distance, a unique pair of witness points is produced, and the signed distance is also evaluated.\n",
    "When computing the collision, an effort is made to compute all the contact points, and early stop can be activated to reduce the algorithm cost as soon as a collision is found. \n",
    "All in all, for this initiation, both can be considered quite similarly.\n",
    "\n",
    "Both functions are parametrized by a *request* object, and write their output in a *result* object. *Request* and *result* objects are preallocated in the geometry data, one of each for each pair of collisions. If you activate or deactivate a collision pair, you have to regenerate these objects (and so if you add a new geometry object in the list). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3e5096c-357f-43f1-a902-bca73cb960f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geom_model.collisionPairs), len(geom_data.collisionRequests), len(geom_data.distanceResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5357039c-51ea-400d-b289-06ceaa3235ff",
   "metadata": {},
   "source": [
    "The placement of the geometry objects with respect to world frame are stored in geom_data.oMg, and computed as\n",
    "$$^oM_g(q) = ^oM_i(q) ^iM_g$$\n",
    "with $^oM_g$ the placement of the object wrt world, $^oM_i$ the placement of the parent joint and $^iM_g$ the (fixed) placement of the object wrt the parent joint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "978eeb5f-c5a6-4e08-b2a4-fb9eb5a85ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(geom_model.geometryObjects),len(geom_data.oMg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71102a56-755d-4612-ab62-6f17ca10a786",
   "metadata": {},
   "source": [
    "This computation is triggered by *pin.updateGeometryPlacements*, after forward kinematics as been run or by forcing the refresh of the forward kinematics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45b06ca0-1010-49d3-b4d5-2256a58a98e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin.updateGeometryPlacements(model,data,geom_model,geom_data,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc670d9-cf14-4c1e-b531-4940201083ae",
   "metadata": {},
   "source": [
    "The computation of the distances and collisions is triggered by their respective function and by default forces the kinematic update.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a81a5c8-3125-449b-8d6f-f92466028c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pin.computeCollisions(model,data,geom_model,geom_data,q)\n",
    "pin.computeDistances(model,data,geom_model,geom_data,q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f6dc9a-01b4-4352-a032-b198952e3510",
   "metadata": {},
   "source": [
    "These two functions actually iterate over each pair and run *pin.computeDistance* or *pin.computeCollision*, which in turn runs *hppfcl.distance* and *hppfcl.collide*. \n",
    "HPP-FCL only works with geometry placements, ignoring the kinematics and the configuration space which is provided by Pinocchio.\n",
    "All these functions have very similar signatures, and Pinocchio is mostly doing a basing wrapping around the HPP-FCL library and gently connected the forward kinematics with the collision algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86846c1-dbc5-49f3-a340-9fdbe8331ce6",
   "metadata": {},
   "source": [
    "### The *result* objects\n",
    "The distance result contains the pair of witness points $p_1$ and $p_2$, the normal direction pointing from $p_1$ to $p_2$ and the signed distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "561bb912-6d6f-498d-9bed-41688a13f800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1: [ 0.13923644 -0.3030054  -0.14295444]\n",
      "p2: [ 0.12472576 -0.13402196 -0.13027373]\n",
      "n: [-0.08531745  0.99356029  0.07455791]\n",
      "dist: 0.17007869445235735\n",
      "check: [-1.56125113e-17 -1.30104261e-18  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "d = geom_data.distanceResults[0]\n",
    "print(\"p1:\",d.getNearestPoint1())\n",
    "print(\"p2:\",d.getNearestPoint2())\n",
    "print(\"n:\",d.normal)\n",
    "print(\"dist:\",d.min_distance)\n",
    "print(\"check:\",np.cross(d.normal,d.getNearestPoint2()-d.getNearestPoint1())) # The two vectors are parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a31655-e464-4a1d-8380-1dcad5659d29",
   "metadata": {},
   "source": [
    "The collision object contains similar information, but can stores several witness pairs instead of a single one, or none if there is no collisions.\n",
    "The collision is decided based on a security margin, tuned in the collision request object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "366c4117-da54-4730-97b6-da470171dd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin: 0.0\n",
      "Number of collisions: 0\n"
     ]
    }
   ],
   "source": [
    "print('Margin:',geom_data.collisionRequests[0].security_margin)\n",
    "c = geom_data.collisionResults[0]\n",
    "print('Number of collisions:',len(c.getContacts()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e1de8-bb66-4623-aa9d-70e6cf558d48",
   "metadata": {},
   "source": [
    "Now choose a configuration in collision and look at the content of this contact list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2229503f-e182-4318-bd27-c80de57a60d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %do_not_load_snippet tp4/generated/example_find_collisions_find\n",
    "for trial in range(1000):\n",
    "    q = pin.randomConfiguration(model)\n",
    "    col = pin.computeCollisions(model,data,geom_model,geom_data,q)\n",
    "    if col: break\n",
    "assert(col)\n",
    "viz.display(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "834c88c9-6242-4a8c-8281-af03e75e0528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b1', 'b2', 'getNearestPoint1', 'getNearestPoint2', 'normal', 'o1', 'o2', 'penetration_depth', 'pos']\n"
     ]
    }
   ],
   "source": [
    "# %load tp4/generated/example_find_collisions_print\n",
    "for pairId,c in enumerate(geom_data.collisionResults):\n",
    "    if len(c.getContacts())>0:\n",
    "        contact = c.getContact(0)\n",
    "        print([ n for n in dir(contact) if '__' not in n])\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66fa93-c2ed-4d49-8f9d-1eba0cc31756",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## From collision detection to contact model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0133ae-0468-4e77-b481-6686574eaa51",
   "metadata": {},
   "source": [
    "### The maths\n",
    "Once the collision are detected, we have to decide the model of the contact interaction that will happen at this location. It can range from a fixed 3D contact (bilateral), a sliding contact enforcing only constraints along the normal direction, a frictional contact or even a full 6D contact with no degree of freedom between the two corresponding bodies (and many other models you can imagine).\n",
    "To describe the contact model, we best formulate it in a reference frame at the contact location. Here we arbitrarily decide to align the *z* direction of the contact frame with the normal direction (oriented from body 1 to body 2) and set the two other *x* and *y* directions to any arbitrary orthogonal basis of the tangential plane. If the collision distance is exactly 0 (which will never be), the center of the frame should be at the contact point. In practice, we can define either two contact frames at each witness point or a single one at the middle point between both. Since the contact distance will never be large, it should be approximately the same and both solutions are acceptable in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d20a527-ac57-4d2d-9a1a-16a9f95ccaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "OC1 = contact.getNearestPoint1()\n",
    "OC2 = contact.getNearestPoint2()\n",
    "normal = contact.normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b4184-bae0-415c-b7c7-6193f0a7d279",
   "metadata": {},
   "source": [
    "From these vectors, build the two contact frames $^oM_{c1}$ and $^oM_{c2}$ centered in $c_1$  and $c_2$ and with *z* axis aligned with the *normal* direction. You can for example use the pin.Quaternion.FromTwoVectors(v1,v2) function, which returns a rotation $r(.)$ such that $r(v_1)=v_2$ ie that transforms $v_1$ into $v_2$ (here we want to transform the *z* axis $z=[0,0,1]$ into the *normal* vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21241041-5ef2-49c1-ba5c-6629c934759a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/create_rigid_contact_models_for_hppfcl_frames\n",
    "pair = geom_model.collisionPairs[pairId]\n",
    "gid1,gid2 = pair.first,pair.second\n",
    "g1 = geom_model.geometryObjects[gid1]\n",
    "g2 = geom_model.geometryObjects[gid2]\n",
    "jid1 = g1.parentJoint \n",
    "jid2 = g2.parentJoint \n",
    "oMj1 = data.oMi[jid1]\n",
    "oMj2 = data.oMi[jid2]\n",
    "\n",
    "# Compute translation and rotation of the contact placements\n",
    "# If dist=0, both placements are identical (and should be somehow close\n",
    "# when dist is reasonibly small).\n",
    "quat = pin.Quaternion.FromTwoVectors(pin.ZAxis,normal) # orientation of the contact frame wrt world\n",
    "assert(np.isclose(quat.norm(),1))\n",
    "oMc1 = pin.SE3(quat.matrix(),OC1) # Placement of first contact frame in world\n",
    "oMc2 = pin.SE3(quat.matrix(),OC2) # Placement of second contact frame in world\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be01ed8-bde7-4190-a4a8-818c71bec31f",
   "metadata": {},
   "source": [
    "The pin.RigidConstaintModel class in Pinocchio conveniently stores these contact quantities: the two parent joints that carries the corresponding colliding bodies, the placements of the contact frames with respect to the joint frames $^{j1}M_{c1}$, $^{jc}M_{c2}$, and a flag specifying if the contact model is 3D (point contact) or 6D (surface contact), which will later be convenient to evaluate the corresponding Jacobian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9e03990-39fd-4d3a-8621-d0db52b6432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/create_rigid_contact_models_for_hppfcl_model\n",
    "contact_model = pin.RigidConstraintModel(\n",
    "        pin.ContactType.CONTACT_3D,\n",
    "        model,\n",
    "        jid1,oMj1.inverse()*oMc1,\n",
    "        jid2,oMj2.inverse()*oMc2,\n",
    "        pin.LOCAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1620531-4dda-40d0-9469-db87263cce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contact_data = contact_model.createData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab5875-8d73-442f-9ff0-9e964b035584",
   "metadata": {},
   "source": [
    "### Creation wrapper\n",
    "This code has been conveniently wrapped in a dedicated function, that takes all the collision or distance results and returns a list of contact models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af53a163-e1e6-4f18-8e7a-8ea5880694ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp4.create_rigid_contact_models_for_hppfcl import createContactModelsFromCollisions,createContactModelsFromDistances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "380d3dd5-740a-4142-bf27-3ca9fd9eeccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/create_rigid_contact_models_for_hppfcl_example\n",
    "pin.computeCollisions(model,data,geom_model,geom_data,q,False)\n",
    "contact_models = createContactModelsFromCollisions(model,data,geom_model,geom_data)\n",
    "contact_datas = [ cm.createData() for cm in contact_models ]\n",
    "\n",
    "pin.computeDistances(model,data,geom_model,geom_data,q)\n",
    "contact_models = createContactModelsFromDistances(model,data,geom_model,geom_data,\n",
    "                                                       threshold=10) # threshold in meter\n",
    "contact_datas = [ cm.createData() for cm in contact_models ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9593582-6095-4c11-a69b-228402cb6635",
   "metadata": {},
   "source": [
    "### Display the contact models\n",
    "A robot description (like the robot URDF) typically describes two sets of geometries: a first set, accurate, detailled and texture fore visualization and non real-time evaluations (called the *visual* model); a second one, less detailed, sometimes approximated or convexified, for efficient computations (often called the *collision* model).\n",
    "\n",
    "Let's display in the 3D viewer the contact models with red contact patches (disks) located at the center of the contact frames and aligned with the *x-y* contact plane. \n",
    "To make it easy to render, we will put these patches in the *visual* model of the system. \n",
    "A fix set of patches is preallocated at initialization (and hidden or displaced far from the scene center when not useful). When contacts are created, the patches are revealed and properly place for rendering.\n",
    "The functions in the file display_collision_patches have be written for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12e9c358-cf30-4fd9-a683-cad9b0c630d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp4.display_collision_patches import preallocateVisualObjects,updateVisualObjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "471e4424-bdbc-4aa9-a37a-6687d1c1ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** You asked to start meshcat \"classically\" in tcp://127.0.0.1:6000\n",
      "*** Did you start meshcat manually (meshcat-server)\n",
      "Wrapper tries to connect to server <tcp://127.0.0.1:6000>\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "# %load tp4/generated/example_display_collision_patches_create\n",
    "# Obtained by simply copying the collision model\n",
    "visual_model = geom_model.copy()\n",
    "preallocateVisualObjects(visual_model)\n",
    "\n",
    "# Start meshcat\n",
    "viz = MeshcatVisualizer(model=model, collision_model=geom_model,\n",
    "                        visual_model=visual_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ef3e4c3-5ef5-47df-97dd-970e710dfe06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9328dfd-db74-4940-a923-e8113e4e83a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_display_collision_patches_display\n",
    "updateVisualObjects(model,data,contact_models,contact_datas,visual_model,viz)\n",
    "viz.display(q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b536e4-2388-40bc-a990-c54b04d3b596",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##  Building a (very) simple kinematic simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824cecd-cb7f-42d8-baf3-6f925610e67c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Let's build a very simple collision simulator. Starting from an initial configuration where some bodies are colliding, you have to choose a velocity of each body to disentangle the colliding parts.\n",
    "The scene created above is composed of 3 bodies, each attached to a \"free-flyer\" joint. The configuration of the scene is the concatenation of the configuration of each joint, corresponding to translation and quaternion describing the placement of each body. The configuration velocity also is the concatenation of the velocity of each body, each corresponding to the spatial velocity $\\nu = (v,\\omega)$ of each body expressed in the local frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ddf6c029-3b70-43be-9d58-bf28fd152aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_separate_objects_hyperparams\n",
    "# HYPER PARAMETERS OF THE PUSH STRATEGY\n",
    "PUSH_FACTOR = .1\n",
    "EPSILON = 1e-1\n",
    "NB_ITER = 100\n",
    "# Compute the contact information based on distances or collisions?\n",
    "USE_DISTANCE = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f376e938-3fe0-4c1f-8d86-f1a366f02479",
   "metadata": {},
   "source": [
    "At each iteration, you have to choose a configuration velocity, then integrate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "98ccc6e4-d045-4715-bf1b-6bdf98bfe20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set minimal distance to be EPSILON\n",
    "# (can be zero, but the rendering is less clear).\n",
    "for r in geom_data.collisionRequests:\n",
    "    r.security_margin = EPSILON\n",
    "\n",
    "# Keep distance history for active pairs (indexed by contact name)\n",
    "h_dist = {}\n",
    "\n",
    "# Iteratively push the colliding pairs ...\n",
    "for i in range(NB_ITER):\n",
    "\n",
    "    # We will compute a change of configuration dq.\n",
    "    # 0 if no active pair.\n",
    "    dq = np.zeros(model.nv)\n",
    "\n",
    "    # Compute the collision at current configuration.\n",
    "    if USE_DISTANCE:\n",
    "        pin.computeDistances(model,data,geom_model,geom_data,q)\n",
    "    else:\n",
    "        pin.computeCollisions(model,data,geom_model,geom_data,q)\n",
    "\n",
    "    # From hppfcl contact information, build a pin.RigidContactModel\n",
    "    if USE_DISTANCE:\n",
    "        contact_models = createContactModelsFromDistances(model,data,geom_model,geom_data,EPSILON)\n",
    "    else:\n",
    "        contact_models = createContactModelsFromCollisions(model,data,geom_model,geom_data)\n",
    "    contact_datas = [ cm.createData() for cm in contact_models ]\n",
    "\n",
    "    # For each detected contact ...\n",
    "    for cmodel,cdata in zip(contact_models,contact_datas):\n",
    "\n",
    "        # Recover contact information\n",
    "        jid1 = cmodel.joint1_id\n",
    "        j1Mc1 = cmodel.joint1_placement\n",
    "        jid2 = cmodel.joint2_id\n",
    "        j2Mc2 = cmodel.joint2_placement\n",
    "\n",
    "        # Compute signed distance\n",
    "        oMc1 = cdata.oMc1 = data.oMi[jid1]*j1Mc1\n",
    "        oMc2 = cdata.oMc2 = data.oMi[jid2]*j2Mc2\n",
    "        dist = oMc1.actInv(oMc2.translation)[2]-EPSILON  # signed distance\n",
    "        \n",
    "        # ### TODO\n",
    "        # Here, do something to the velocity of the two joints carrying the \n",
    "        # two colliding bodies.\n",
    "        # Displacement for body 1\n",
    "        dq[model.idx_vs[jid1]:model.idx_vs[jid1]+6] += 0 ### TODO FIX ME\n",
    "        # Displacement for body 2\n",
    "        dq[model.idx_vs[jid2]:model.idx_vs[jid2]+6] -= 0 ### TODO FIX ME\n",
    "        \n",
    "        # Log the distance in h_dist for future plot\n",
    "        if cmodel.name not in h_dist:\n",
    "            h_dist[cmodel.name] = np.zeros(NB_ITER)\n",
    "        h_dist[cmodel.name][i] = dist\n",
    "\n",
    "    # Finally, modify the current config q with the push dq\n",
    "    q = pin.integrate(model,q,dq)\n",
    "\n",
    "    # Display the current configuration\n",
    "    if i % 10 == 0:\n",
    "        # Meshcat is slow to display the patches, display once in a while\n",
    "        updateVisualObjects(model,data,contact_models,contact_datas,visual_model,viz)\n",
    "        viz.display(q)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8894c-9de6-42b6-af52-6e324a5b49ad",
   "metadata": {},
   "source": [
    "If you don't have any strong ideas, you can start to compute a \"push\" repulsive 3D velocity that the first witness point should adopt. The second witness point should likely adopt the opposite velocity. This is the value of the velocity vector field at the contact point. Now choose the spatial velocity at the center of the body so that the value of the corresponding vector field matches. In a first trial, a spatial velocity with 0 angular velocity $\\omega$ should be evident to guess. Can you imagine a more efficient linear+angular velocity that would work as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5887d564-28be-44d3-91d6-fc6a0cdb2633",
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load_snippet tp4/generated/example_separate_objects_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b76549-262f-46d9-b75c-4a5e5d70bc22",
   "metadata": {},
   "source": [
    "### With a more complex scene\n",
    "Now let's load a square jar full of pills. Run the same algorithm on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3585bdd1-c846-426e-9a54-d003d6814eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** You asked to start meshcat \"classically\" in tcp://127.0.0.1:6000\n",
      "*** Did you start meshcat manually (meshcat-server)\n",
      "Wrapper tries to connect to server <tcp://127.0.0.1:6000>\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    }
   ],
   "source": [
    "# %load tp4/generated/scenes_pills\n",
    "model,geom_model = buildScenePillsBox(seed=2,nobj=30,wall_size=2.0,one_of_each=True)\n",
    "visual_model = geom_model.copy()\n",
    "viz = MeshcatVisualizer(model=model, collision_model=geom_model,\n",
    "                        visual_model=geom_model)\n",
    "\n",
    "# Generate colliding configuration\n",
    "data = model.createData()\n",
    "geom_data = geom_model.createData()\n",
    "for i in range(10):\n",
    "    q0 = pin.randomConfiguration(model)\n",
    "    pin.computeCollisions(model,data,geom_model,geom_data,q0)\n",
    "    if sum([ len(c.getContacts()) for c in geom_data.collisionResults ])>10:\n",
    "        break\n",
    "    print(sum([ len(c.getContacts()) for c in geom_data.collisionResults ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cd5d3db6-c91e-4ab7-a96e-962a8d6b9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = q0.copy()\n",
    "viz.display(q)\n",
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f92a3c-0466-4d93-8b83-b944a165afc2",
   "metadata": {},
   "source": [
    "You can plot the convergence of the colliding bodies from initial negative (penetration) distance to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb3fa62-81f3-437c-99ac-91e89ff0ee7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6ddc2d5ae0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load tp4/generated/example_separate_objects_plot\n",
    "# Plot the distances\n",
    "for k,v in h_dist.items():\n",
    "    h = plt.plot(v,label=k)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb91c3a0-29fe-4698-bf96-4a6866b3c2af",
   "metadata": {},
   "source": [
    "## Contact-less simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d6b2f-287e-4597-8317-a88ca332d0b6",
   "metadata": {},
   "source": [
    "We now have all the contact information, let's look at the system dynamics. \n",
    "We will write a contact-less simulator, just integrating free fall.\n",
    "Better use an actuated model for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfddd1ca-d298-4fed-99a0-d98d397d8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Model of a robot hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bef3f77c-f77c-48b3-ae33-cb2d8d3ab503",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,geom_model = buildSceneRobotHand()\n",
    "q0 = model.referenceConfigurations['default']\n",
    "data = model.createData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4be91b2-09da-4f16-ba4a-0f2afb836164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** You asked to start meshcat \"classically\" in tcp://127.0.0.1:6000\n",
      "*** Did you start meshcat manually (meshcat-server)\n",
      "Wrapper tries to connect to server <tcp://127.0.0.1:6000>\n",
      "You can open the visualizer by visiting the following URL:\n",
      "http://127.0.0.1:7000/static/\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"height: 400px; width: 100%; overflow-x: auto; overflow-y: hidden; resize: both\">\n",
       "            <iframe src=\"http://127.0.0.1:7000/static/\" style=\"width: 100%; height: 100%; border: none\"></iframe>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visual_model = geom_model.copy()\n",
    "viz = MeshcatVisualizer(model=model, collision_model=geom_model,\n",
    "                        visual_model=geom_model)\n",
    "viz.display(q0)\n",
    "viz.viewer.jupyter_cell()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eeeac2-e7d8-4f8a-a859-e052c48cbbdf",
   "metadata": {},
   "source": [
    "### Evaluating the core elements of the dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e699d99-7762-4d7a-991f-5c216cd2bf6f",
   "metadata": {},
   "source": [
    "In a first time, let's play with the dynamics without constraints.\n",
    "Choosing an arbitrary joint torque $\\tau_q$, inocchio can compute the robot acceleration and integrate it.\n",
    "The dynamic equation of the robot is $M a_q + b = \\tau_q$, with $M$ the mass, $a_q$ the joint acceleration and $b$ the drift.\n",
    "The mass matrix can be computed using *CRB* algorithm (function of q). The drift is computed using *NLE* (nonlinear effects) algorithm (function of $q$, $v_q$). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ea3d313-e91c-4245-bc8a-4cf65250a7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_control_init\n",
    "q = q0.copy()\n",
    "vq = np.zeros(model.nv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eabd9644-416f-405e-ae67-2649f321a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_control_mass\n",
    "M = pin.crba(model, data, q)\n",
    "b = pin.nle(model, data, q, vq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605402bf-8821-48fd-934b-6402f58c9ca5",
   "metadata": {},
   "source": [
    "These terms correspond to the inverse dynamics. They can be numerically inverted to compute the direct dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed96e4c-4fa5-4e89-a8a8-c4a1ff0d60ed",
   "metadata": {},
   "source": [
    "Using $M$ and $b$ computed by the above algorithms, and knowing a given set of joint torques $\\tau_q$, how would you compute $a_q$ so that $M a_q + b = \\tau_q$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3df4112-e5d9-41e1-a6b0-e5962e27cf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load_snippet tp4/generated/example_control_dyninv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fc322-9386-44c8-aa28-bff401ac306e",
   "metadata": {},
   "source": [
    "The inverse-dynamics algorithm indeed compute the needed torques to achieve a given acceleration. We can use the *RNEA* function to double-check our result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2fe4be72-214c-4339-b190-b44d08c58529",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(pin\u001b[38;5;241m.\u001b[39mrnea(model,data,q,vq,\u001b[43maq\u001b[49m)\u001b[38;5;241m-\u001b[39mtauq)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pin\u001b[38;5;241m.\u001b[39mrnea(model,data,q,vq,vq\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m-\u001b[39mpin\u001b[38;5;241m.\u001b[39mnle(model,data,q,vq))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'aq' is not defined"
     ]
    }
   ],
   "source": [
    "print(pin.rnea(model,data,q,vq,aq)-tauq)\n",
    "print(pin.rnea(model,data,q,vq,vq*0)-pin.nle(model,data,q,vq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26d663-0265-465f-a066-07b4de29b3f9",
   "metadata": {},
   "source": [
    "### Integrating the acceleration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d09e3bf-5b3f-4270-b5a6-a1c9a94862bd",
   "metadata": {},
   "source": [
    "Once aq as been computed, it is straight forward to integrate it to velocity using $v_q += a_q \\Delta t$. \n",
    "Integration to joint position is more complex in general, as we saw for the mobile robot. Here, $n_q = n_v$ and everything is Euclinea, so a simple += integration would work, but since it is implemented in pinocchio, let's keep the good habits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ba7b9-68ad-497b-9424-0d93600f02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = 5e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4759743f-b58b-497e-b744-2310d9961aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_control_integrate\n",
    "vq += aq * DT\n",
    "q = pin.integrate(model, q, vq * DT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbd473-521d-49d7-9aaf-17dd505fd369",
   "metadata": {},
   "source": [
    "Now, you should be able to implement a first simulation (not a rendering any more) of the robot behavior when no torque is applied (tauq = 0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fb0d18-32ba-4db5-aa54-433441c2ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tauq = np.zeros(robot.model.nv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a6bc5-bae7-47e7-99ac-938ff453c166",
   "metadata": {},
   "source": [
    "Fill the template below to get a free-falling dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3945eb-cb66-49b9-b9d7-3013b9a91eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(1000):\n",
    "    t = it*dt\n",
    "    ### Compute acceleration instead of this comment\n",
    "    ### Integrate the acceleration twice instead of this comment\n",
    "    \n",
    "    if i%20==0: \n",
    "        robot.display(q)\n",
    "        time.sleep(20*dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2450db49-f72d-4b00-8ea4-944597427b20",
   "metadata": {},
   "source": [
    "Now modify the simulator to encompass joint friction, i.e. the torque is opposite to the velocity with a friction coefficient $K_f$ (take $K_f=0.1$ as a start)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510da04b-0334-4158-b835-b0ff6175c2f7",
   "metadata": {},
   "source": [
    "## (optional) Reference trajectory\n",
    "If you like it, a class is implemented to compute a reference trajectory as a sinus with various frequency, phase and amplitude on each joint. It is implemented in traj_ref with the class TrajRef."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d71cb37-b381-420f-9c2e-87ea343acfcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tp4.traj_ref import TrajRef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be658b2-4eb7-457f-b294-6c57f80c1f4f",
   "metadata": {},
   "source": [
    "In this simple example, we define a trajectory in dimension 3, starting at t=0 from q=[0,0,0], with 3 sinusoid of frequency 1,2 and 3, all with the same amplitude 1.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f591cf-cfe7-4983-96e1-1256d599fe15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load  tp4/generated/traj_ref_main\n",
    "qdes = TrajRef(np.array([0,0,0.]),omega = np.array([1,2,3.]),amplitude=1.5)\n",
    "t = 0.2\n",
    "print(qdes(t),qdes.velocity(t),qdes.acceleration(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f98d5-17c1-4759-8b3c-b071b6a12726",
   "metadata": {},
   "source": [
    "## Proportional-derivative and computed torque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73df67e-9a36-44b0-a630-871923d88262",
   "metadata": {},
   "source": [
    "Now choose a reference joint position (possibly time varying, like in the hand example).\n",
    "The joint torques can then be computed to track the desired position, with $\\tau_q = -K_p (q-q^{des}) - K_v v_q$. Both gains $K_p$ and $K_v$ should be properly chosen. Optimal tracking is obtained with $K_v = 2 \\sqrt{K_p}$. \n",
    "In general, a desired velocity is also tracked to avoid tracking errors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600b351e-3907-4b2c-9166-379cf916e4f0",
   "metadata": {},
   "source": [
    "First choose the PD gains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a40cc6-4fb9-4ad9-b90f-d24ee51a23b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_control_hyper\n",
    "# Hyperparameters for the control and the simu\n",
    "Kp = 50.               # proportional gain (P of PD)\n",
    "Kv = 2 * np.sqrt(Kp)   # derivative gain (D of PD)\n",
    "dt = 1e-3              # simulation timestep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db361dde-d485-452f-bc09-8c8f56b98482",
   "metadata": {},
   "source": [
    "Then choose the reference trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a72e68-c72d-4d7c-a418-cd9857830fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_control_trajref\n",
    "from tp4.traj_ref import TrajRef\n",
    "qdes = TrajRef(robot.q0,omega = np.array([0,.1,1,1.5,2.5,-1,-1.5,-2.5,.1,.2,.3,.4,.5,.6]),amplitude=1.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44de3e5c-cee5-4961-9b5f-962f3fbc9c04",
   "metadata": {},
   "source": [
    "Finally, implement the control loop using the following template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151088bb-225f-48c8-b912-b7d4310f7ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tp4/generated/example_control_loop\n",
    "hq    = []   ### For storing the logs of measured trajectory q\n",
    "hqdes = []   ### For storing the logs of desired trajectory qdes\n",
    "for i in range(10000):\n",
    "    t = i*dt\n",
    "\n",
    "    # Compute the PD control.\n",
    "    tauq = np.zeros(robot.model.nv)   # REPLACE ME\n",
    "    \n",
    "    # Compute the model M and b.\n",
    "    M = np.eye(robot.model.nv)        # REPLACE ME\n",
    "    b = np.zeros(robot.model.nv)      # REPLACE ME\n",
    "    \n",
    "    # Simulated the resulting acceleration (forward dynamics\n",
    "    aq = np.zeros(robot.model.nv)     # REPLACE ME\n",
    "\n",
    "    # Integrate the acceleration.\n",
    "    vq += np.zeros(robot.model.nv)    # REPLACE ME\n",
    "    q  = q+np.zeros(robot.model.nv)   # REPLACE ME\n",
    "\n",
    "    # Display every TDISP iterations.\n",
    "    TDISP = 50e-3    # Display every 50ms\n",
    "    if not i % int(TDISP/dt):  # Only display once in a while ...\n",
    "        viz.display(q)\n",
    "        time.sleep(TDISP)\n",
    "\n",
    "    # Log the history.\n",
    "    hq.append(q.copy())\n",
    "    hqdes.append(qdes.copy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6093fa-1272-4ed4-8b2c-05923775f5c0",
   "metadata": {},
   "source": [
    "Here is the solution, should you need it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5a0a78-2d37-4aef-bc69-c1b78be422b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%do_not_load_snippet tp4/generated/example_control_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb42d3e-a9d0-4477-8c69-49c6f1b844a8",
   "metadata": {},
   "source": [
    "Here, there is a strong coupling between joints, due to the mass matrix that is not compensated in the simple PD law. In theory, the computed torques is to compute the joint torque by inverse dynamics from a reference joint acceleration. This boils down to canceling the simulation equation by choosing the proper terms in the control law. It is now very interesting to implement in case of perfect dynamics knowledge. It might be more interesting to study in case the simulation is done with the perfect M, while the control is computed with approximate M (for example, using only the diagonal terms of the mass matrix). Let's rather simulate contact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7464b1c-33e2-49a0-9039-bdbfc4a23113",
   "metadata": {},
   "source": [
    "It is intersting to plot the results. In the solution of the previous example, the effective and desired position q and qdes have been stored in a log list. We can display them with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f51f49-0b09-41f4-926d-e9d09e5e38e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "plt.plot([q[2] for q in hq])\n",
    "plt.plot([q[2] for q in hqdes])\n",
    "plt.ylabel('Joint #2')\n",
    "plt.subplot(212)\n",
    "plt.plot([q[3] for q in hq])\n",
    "plt.plot([q[3] for q in hqdes]);\n",
    "plt.ylabel('Joint #1')\n",
    "plt.xlabel('Iterations')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
